---
phase: 03-schema-and-quality-system
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - backend/app/db/migrations/versions/005_add_quality_and_web_thickness.py
  - backend/app/models/powder.py
  - backend/app/core/quality.py
  - backend/app/schemas/powder.py
  - backend/app/api/powders.py
  - backend/app/api/simulate.py
  - backend/app/seed/initial_data.py
autonomous: true
requirements:
  - PWD-02
  - PWD-03
  - PWD-04
  - QLT-02
  - QLT-03
  - SOL-01

must_haves:
  truths:
    - "GET /powders returns quality_score, data_source, quality_level, and quality_tooltip for each powder"
    - "POST /powders creates a powder with data_source='manual' and a computed quality_score"
    - "PUT /powders/{id} auto-recomputes quality_score after applying field changes"
    - "PUT on a grt_community powder changes data_source to grt_modified"
    - "Simulation with a powder that has web_thickness_mm set uses that value instead of 0.0004m default"
    - "Simulation with a powder that has web_thickness_mm=NULL uses 0.0004m fallback and adds a warning"
  artifacts:
    - path: "backend/app/core/quality.py"
      provides: "Deterministic quality scoring function"
      exports: ["compute_quality_score", "QualityBreakdown", "CRITICAL_FIELDS", "BONUS_FIELDS"]
    - path: "backend/app/db/migrations/versions/005_add_quality_and_web_thickness.py"
      provides: "Alembic migration adding data_source, quality_score, web_thickness_mm to powders"
      contains: "op.add_column"
    - path: "backend/app/models/powder.py"
      provides: "ORM columns for data_source, quality_score, web_thickness_mm"
      contains: "data_source"
    - path: "backend/app/schemas/powder.py"
      provides: "PowderResponse with quality_level and quality_tooltip computed fields"
      contains: "quality_tooltip"
  key_links:
    - from: "backend/app/api/powders.py"
      to: "backend/app/core/quality.py"
      via: "compute_quality_score() called in create_powder and update_powder"
      pattern: "compute_quality_score"
    - from: "backend/app/api/simulate.py"
      to: "backend/app/models/powder.py"
      via: "reads powder.web_thickness_mm in _make_params()"
      pattern: "web_thickness_mm"
    - from: "backend/app/schemas/powder.py"
      to: "backend/app/core/quality.py"
      via: "quality_tooltip computed_field calls compute_quality_score"
      pattern: "compute_quality_score"
---

<objective>
Add data provenance, quality scoring, and per-powder web_thickness to the backend: Alembic migration for 3 new columns, deterministic quality scorer module, auto-recompute on create/update, solver reads web_thickness from DB.

Purpose: Every powder record carries a computed quality score (0-100) and data source provenance so users can assess data reliability. The solver uses per-powder web_thickness for improved accuracy.
Output: Quality scoring system fully functional via API, solver parameterized per-powder.
</objective>

<execution_context>
@C:/Users/vall-/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/vall-/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-schema-and-quality-system/03-RESEARCH.md
@.planning/phases/03-schema-and-quality-system/03-CONTEXT.md
@backend/app/models/powder.py
@backend/app/schemas/powder.py
@backend/app/api/powders.py
@backend/app/api/simulate.py
@backend/app/seed/initial_data.py
@backend/app/db/migrations/versions/004_add_3curve_columns.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Alembic migration, ORM columns, and quality scorer module</name>
  <files>
    backend/app/db/migrations/versions/005_add_quality_and_web_thickness.py
    backend/app/models/powder.py
    backend/app/core/quality.py
  </files>
  <action>
**1. Create Alembic migration `005_add_quality_and_web_thickness.py`:**
- Follow exact naming convention from `004_add_3curve_columns.py`
- `revision = "005_quality_web_thickness"`, `down_revision = "004_3curve_cols"`
- Add 3 columns to `powders` table:
  - `data_source`: `String(20)`, `nullable=False`, `server_default="manual"`
  - `quality_score`: `Integer`, `nullable=False`, `server_default="0"`
  - `web_thickness_mm`: `Float`, `nullable=True`
- Downgrade drops all 3 columns in reverse order

**2. Add ORM columns to `backend/app/models/powder.py`:**
- After existing columns, add:
  - `data_source = Column(String(20), nullable=False, default="manual")` -- Python default for ORM inserts in tests (create_all bypasses Alembic)
  - `quality_score = Column(Integer, nullable=False, default=0)`
  - `web_thickness_mm = Column(Float, nullable=True)`
- Import `String, Integer` from sqlalchemy if not already imported

**3. Create `backend/app/core/quality.py`:**
- Define `CRITICAL_FIELDS` list: `burn_rate_coeff`, `burn_rate_exp`, `force_constant_j_kg`, `covolume_m3_kg`, `flame_temp_k`, `gamma`, `density_g_cm3` (7 fields the solver requires)
- Define `BONUS_FIELDS` list: `web_thickness_mm`, `ba`, `bp`, `br`, `brp`, `z1`, `z2` (7 fields that improve accuracy)
- Define `SOURCE_SCORES` dict: `manufacturer=100`, `grt_community=75`, `grt_modified=55`, `manual=35`, `estimated=10`
- Create `QualityBreakdown` dataclass: `score: int`, `completeness_score: int`, `source_score: int`, `filled_count: int`, `total_count: int`, `missing_fields: list[str]`, `data_source: str`
- Implement `compute_quality_score(powder_dict: dict, data_source: str) -> QualityBreakdown`:
  - Count critical fields filled (non-None values in powder_dict)
  - Count bonus fields filled
  - Completeness: critical fields weighted 2x. `max_weighted = len(CRITICAL_FIELDS) * 2 + len(BONUS_FIELDS)`. `weighted_filled = critical_filled * 2 + bonus_filled`. `completeness_pct = round(100 * weighted_filled / max_weighted)`
  - Source score: lookup from `SOURCE_SCORES`, default 10
  - Final score: `round(0.30 * completeness_pct + 0.70 * source_pct)`
  - Missing fields: list of field names from CRITICAL + BONUS where value is None
  - Return QualityBreakdown with all computed values
  - This function is pure (no DB access, no side effects) and deterministic
  </action>
  <verify>
Run: `cd backend && python -c "from app.core.quality import compute_quality_score, CRITICAL_FIELDS, BONUS_FIELDS, QualityBreakdown; print('OK')"` succeeds.
Run: `cd backend && python -c "from app.core.quality import compute_quality_score; r = compute_quality_score({'burn_rate_coeff': 1, 'burn_rate_exp': 0.8, 'force_constant_j_kg': 1e6, 'covolume_m3_kg': 0.001, 'flame_temp_k': 3000, 'gamma': 1.2, 'density_g_cm3': 1.6}, 'grt_community'); print(r.score, r.filled_count, r.total_count, r.missing_fields)"` prints score ~72, filled=7, total=14, missing 7 bonus fields.
Run: `cd backend && python -c "from app.models.powder import Powder; print([c.key for c in Powder.__table__.columns if c.key in ('data_source','quality_score','web_thickness_mm')])"` prints all 3 column names.
  </verify>
  <done>
quality.py module exists with deterministic scorer. ORM has 3 new columns. Migration file follows project conventions. Critical fields weighted 2x in completeness calculation. Source reliability is 70% of final score per user decision.
  </done>
</task>

<task type="auto">
  <name>Task 2: Schemas, CRUD auto-recompute, and solver web_thickness passthrough</name>
  <files>
    backend/app/schemas/powder.py
    backend/app/api/powders.py
    backend/app/api/simulate.py
    backend/app/seed/initial_data.py
  </files>
  <action>
**1. Update `backend/app/schemas/powder.py`:**

In `PowderCreate`:
- Add `data_source: str = Field(default="manual", description="Data source provenance")` -- default "manual" for user-created powders
- Add `web_thickness_mm: float | None = Field(default=None, ge=0.1, le=2.0, description="Propellant grain web thickness (mm)")` -- nullable with physical bounds (0.1-2.0mm covers all powder geometries)
- Do NOT add quality_score to Create (it is computed, not user-supplied)

In `PowderUpdate`:
- Add `data_source: str | None = None` -- optional, user can override
- Add `web_thickness_mm: float | None = None` -- optional update

In `PowderResponse`:
- Add `data_source: str = "manual"`
- Add `quality_score: int = 0`
- Add `web_thickness_mm: float | None = None`
- Add `@computed_field` `quality_level` property: returns `"success"` if score >= 70, `"warning"` if score >= 40, else `"danger"` (maps to existing Badge component variants)
- Add `@computed_field` `quality_tooltip` property: calls `compute_quality_score(self.model_dump(), self.data_source)` to get breakdown, then builds one-line summary string in format: `"{score}/100 â€” {source_label}, {filled}/{total} campos, faltan: {missing_list}"`. Source labels: manufacturer="Fabricante", grt_community="GRT Community", grt_modified="GRT Modificado", manual="Manual", estimated="Estimado". Show first 3 missing fields, append `(+N)` if more. If no missing fields, omit the "faltan:" part.

**2. Update `backend/app/api/powders.py`:**

In `create_powder`:
- After `powder = Powder(**data.model_dump())`, import and call `compute_quality_score`:
  ```python
  from app.core.quality import compute_quality_score
  powder_dict = data.model_dump()
  breakdown = compute_quality_score(powder_dict, powder.data_source)
  powder.quality_score = breakdown.score
  ```
- Then add, commit, refresh as before

In `update_powder`:
- After applying `setattr(powder, key, value)` loop, add:
  ```python
  # Track source modification: GRT -> grt_modified on edit
  if powder.data_source == "grt_community":
      powder.data_source = "grt_modified"
  # Recompute quality score
  from app.core.quality import compute_quality_score
  powder_dict = {c.key: getattr(powder, c.key) for c in Powder.__table__.columns}
  breakdown = compute_quality_score(powder_dict, powder.data_source)
  powder.quality_score = breakdown.score
  ```
- Then commit, refresh as before

In `import_grt_powders`:
- After creating each powder from GRT data, set `data_source="grt_community"` explicitly on the Powder object before adding to session
- Compute quality score for each imported powder and set `powder.quality_score = breakdown.score`

**3. Update `backend/app/api/simulate.py`:**

In `_make_params()` function, find where `PowderParams` is constructed. Change the `web_thickness_m` parameter:
- Before: uses hardcoded `0.0004` or whatever the current default is
- After:
  ```python
  web_thickness_m = (
      powder.web_thickness_mm * 0.001
      if powder.web_thickness_mm is not None
      else 0.0004  # legacy default
  )
  ```
- Pass `web_thickness_m=web_thickness_m` to `PowderParams()`
- Add a warning to the warnings list when using default: `"Usando espesor de alma predeterminado (0.4 mm). Para mayor precision, configure web_thickness en la polvora."`
- Note: `powder` here is the ORM row fetched from DB, which now has `web_thickness_mm` attribute

**4. Update `backend/app/seed/initial_data.py`:**
- Add `data_source="manual"` to each seed powder dict (for explicitness, though the ORM default covers it)
- After creating seed powders in the seed function, compute and set quality_score for each:
  ```python
  from app.core.quality import compute_quality_score
  for powder in created_powders:
      powder_dict = {c.key: getattr(powder, c.key) for c in Powder.__table__.columns}
      breakdown = compute_quality_score(powder_dict, powder.data_source)
      powder.quality_score = breakdown.score
  ```
- Commit after setting all scores
  </action>
  <verify>
Run: `cd backend && python -m pytest tests/ -v --tb=short` -- all existing tests still pass (no regressions).
Run: `cd backend && python -c "from app.schemas.powder import PowderResponse; p = PowderResponse(id='00000000-0000-0000-0000-000000000001', name='Test', manufacturer='Test', burn_rate_coeff=1.0, burn_rate_exp=0.8, force_constant_j_kg=1e6, covolume_m3_kg=0.001, flame_temp_k=3000, gamma=1.25, density_g_cm3=1.6, data_source='grt_community', quality_score=72); print(p.quality_level, p.quality_tooltip)"` -- prints "success" and a tooltip string containing "72/100".
  </verify>
  <done>
PowderResponse includes quality_level and quality_tooltip computed fields. create_powder and update_powder auto-compute quality_score. update_powder transitions grt_community to grt_modified. Solver reads web_thickness_mm from powder row with 0.0004m fallback + warning. Seed data sets data_source explicitly. All existing tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 3: Quality scoring and solver web_thickness tests</name>
  <files>
    backend/tests/test_quality.py
    backend/tests/test_api_integration.py
  </files>
  <action>
**1. Create `backend/tests/test_quality.py`** with the following test cases:

```python
import pytest
from app.core.quality import compute_quality_score, QualityBreakdown, CRITICAL_FIELDS, BONUS_FIELDS, SOURCE_SCORES

class TestQualityScoring:
    """Tests for deterministic quality scoring algorithm."""

    def _full_powder_dict(self) -> dict:
        """Powder dict with all critical + bonus fields filled."""
        return {
            "burn_rate_coeff": 8.0e-8, "burn_rate_exp": 0.85,
            "force_constant_j_kg": 1_050_000, "covolume_m3_kg": 0.001,
            "flame_temp_k": 3100, "gamma": 1.24, "density_g_cm3": 1.6,
            "web_thickness_mm": 0.4, "ba": 0.7, "bp": 0.3,
            "br": 0.1, "brp": 0.05, "z1": 0.3, "z2": 0.7,
        }

    def test_manufacturer_full_data_scores_100(self):
        r = compute_quality_score(self._full_powder_dict(), "manufacturer")
        assert r.score == 100
        assert r.missing_fields == []
        assert r.filled_count == 14

    def test_estimated_full_data_below_40(self):
        r = compute_quality_score(self._full_powder_dict(), "estimated")
        assert r.score < 40  # 0.30*100 + 0.70*10 = 37

    def test_manufacturer_with_gaps_beats_estimated_full(self):
        """User decision: manufacturer with gaps > complete estimated."""
        partial = {"burn_rate_coeff": 1.0, "burn_rate_exp": 0.8}
        r_mfr = compute_quality_score(partial, "manufacturer")
        r_est = compute_quality_score(self._full_powder_dict(), "estimated")
        assert r_mfr.score > r_est.score

    def test_deterministic(self):
        """Same inputs always produce same output."""
        d = self._full_powder_dict()
        r1 = compute_quality_score(d, "grt_community")
        r2 = compute_quality_score(d, "grt_community")
        assert r1.score == r2.score
        assert r1.missing_fields == r2.missing_fields

    def test_source_tier_ordering(self):
        d = self._full_powder_dict()
        scores = {src: compute_quality_score(d, src).score for src in SOURCE_SCORES}
        assert scores["manufacturer"] > scores["grt_community"]
        assert scores["grt_community"] > scores["grt_modified"]
        assert scores["grt_modified"] > scores["manual"]
        assert scores["manual"] > scores["estimated"]

    def test_empty_dict_returns_zero_completeness(self):
        r = compute_quality_score({}, "manual")
        assert r.filled_count == 0
        assert r.completeness_score == 0
        assert len(r.missing_fields) == 14

    def test_critical_fields_weighted_double(self):
        """Filling one critical field should increase score more than one bonus field."""
        one_critical = {"burn_rate_coeff": 1.0}
        one_bonus = {"web_thickness_mm": 0.4}
        r_c = compute_quality_score(one_critical, "manual")
        r_b = compute_quality_score(one_bonus, "manual")
        assert r_c.completeness_score > r_b.completeness_score

    def test_unknown_source_defaults_to_10(self):
        r = compute_quality_score({}, "unknown_source")
        assert r.source_score == 10

    def test_score_range_0_to_100(self):
        for src in SOURCE_SCORES:
            r1 = compute_quality_score({}, src)
            r2 = compute_quality_score(self._full_powder_dict(), src)
            assert 0 <= r1.score <= 100
            assert 0 <= r2.score <= 100

    def test_breakdown_dataclass_fields(self):
        r = compute_quality_score(self._full_powder_dict(), "grt_community")
        assert isinstance(r, QualityBreakdown)
        assert isinstance(r.score, int)
        assert isinstance(r.missing_fields, list)
        assert isinstance(r.data_source, str)
        assert r.data_source == "grt_community"
```

**2. Add tests to `backend/tests/test_api_integration.py`** (append new test class):

- `test_create_powder_sets_quality_score`: POST a powder with all critical fields, verify response has `quality_score > 0`, `data_source == "manual"`, `quality_level` is one of success/warning/danger, and `quality_tooltip` contains "/100"
- `test_update_powder_recomputes_quality`: Create powder, PUT with additional field filled, verify quality_score changed
- `test_update_grt_powder_changes_source`: Create powder with `data_source="grt_community"`, PUT any field change, verify response has `data_source == "grt_modified"`
- `test_powder_response_has_quality_tooltip`: GET a powder, verify `quality_tooltip` is a non-empty string containing "/100" and "campos"
- `test_web_thickness_mm_validation_bounds`: POST powder with `web_thickness_mm=0.05` (below 0.1), expect 422. POST with `web_thickness_mm=0.4`, expect 201.
  </action>
  <verify>
Run: `cd backend && python -m pytest tests/test_quality.py -v` -- all 10 tests pass.
Run: `cd backend && python -m pytest tests/test_api_integration.py -v` -- all tests pass (existing + 5 new).
Run: `cd backend && python -m pytest tests/ -v --tb=short` -- full suite passes, report total count.
  </verify>
  <done>
10 unit tests for quality scorer cover: determinism, source tier ordering, critical vs bonus weighting, boundary cases, manufacturer-beats-estimated invariant. 5 integration tests verify API behavior: auto-compute on create, recompute on update, grt_community->grt_modified transition, quality_tooltip format, web_thickness validation bounds. All existing tests still pass.
  </done>
</task>

</tasks>

<verification>
1. `cd backend && python -m pytest tests/ -v --tb=short` -- all tests pass (existing + new quality + integration)
2. `cd backend && python -c "from app.core.quality import compute_quality_score; print(compute_quality_score({}, 'manual').score)"` -- returns a score (24-25 range)
3. `cd backend && python -c "from app.schemas.powder import PowderResponse; print(PowderResponse.__fields__.keys())"` -- includes data_source, quality_score, web_thickness_mm
4. Verify migration file exists: `ls backend/app/db/migrations/versions/005*`
</verification>

<success_criteria>
- Quality scorer is deterministic: same inputs = same score
- 30/70 split between completeness and source reliability per user decision
- Manufacturer with gaps scores higher than complete estimated entry
- PowderResponse includes quality_level (success/warning/danger) and quality_tooltip (one-sentence summary)
- create_powder and update_powder auto-compute quality_score
- update_powder transitions grt_community -> grt_modified
- Solver reads web_thickness_mm from powder row with 0.0004m fallback
- All tests pass (existing + 15 new)
</success_criteria>

<output>
After completion, create `.planning/phases/03-schema-and-quality-system/03-01-SUMMARY.md`
</output>
